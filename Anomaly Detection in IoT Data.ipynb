{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Anomaly Detection in IoT Data Algorithm from AWS Marketplace \n",
    "\n",
    "Imbalance data is a major challenge in anomaly detection domain, with huge non-anomalous data and limited anomalous data. This solution is in sync with data imbalance and is a semi-supervised approach which uses generative deep learning model to learn normal IoT sensor patterns using non-anomalous data and then builds a 1-rule threshold model using data from both classes to identify the anomalous behavior of the sensor using inclusion-exclusion principle. The solution is also re-trainable to capture information drift.\n",
    "\n",
    "This sample notebook shows you how to deploy Anomaly Detection in IoT Data Algorithm using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Healthcare Fraud Detection System.\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the Algorithm](#1.-Subscribe-to-the-Algorithm)\n",
    "2. [Prepare dataset](#2.-Prepare-dataset)\n",
    "    1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "    2. [Configure and visualize train,validation and test dataset](#B.-Configure-and-visualize-train,-validation-and-test-dataset)\n",
    "    3. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "3. [Train a machine learning model](#3.-Train-a-machine-learning-model)\n",
    "    1. [Set up environment](#A.-Set-up-environment)\n",
    "    2. [Train a model](#B.-Train-a-model)\n",
    "4. [Deploy model and verify results](#4.-Deploy-model-and-verify-results)\n",
    "    1. [Deplay trained model](#A.-Deploy-trained-model)\n",
    "    2. [Create input payload](#B.-Create-input-payload)\n",
    "    3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    4. [Visualize output](#D.-Visualize-output)\n",
    "    5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "5. [Perform Batch inference](#5.-Perform-Batch-inference)\n",
    "    1. [Inspect the Batch Transform Output in S3](#A.-Inspect-the-Batch-Transform-Output-in-S3)\n",
    "6. [Clean-up](#6.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the Algorithm:\n",
    "1. Open the algorithm listing page **Anomaly Detection in IoT Data**\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the algorithm ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn ='arn:aws:sagemaker:us-east-2:786796469737:algorithm/anomaly-detection-in-iot-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.algorithm import AlgorithmEstimator\n",
    "from sagemaker import ModelPackage\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployed solution has these **2 steps**: Training the algorithm and Testing\n",
    "\n",
    "<li>: The algorithm trains on user provided dataset.\n",
    "<li>: The train dataset must contain - \"train.csv\" with 'utf-8' encoding.\n",
    "<li>: The machine learning model is trained in the training step and once the model is generated, it can be used to make prediction on test data\n",
    "<li>: The testing API takes a csv file \"test.csv\" and predicts whether the claim is fraudulent or not.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Configure and visualize train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset='data/training/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearing 1</th>\n",
       "      <th>Bearing 2</th>\n",
       "      <th>Bearing 3</th>\n",
       "      <th>Bearing 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2/15/2004 10:32</th>\n",
       "      <td>0.060959</td>\n",
       "      <td>0.074498</td>\n",
       "      <td>0.076289</td>\n",
       "      <td>0.043229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 10:42</th>\n",
       "      <td>0.060307</td>\n",
       "      <td>0.073227</td>\n",
       "      <td>0.075189</td>\n",
       "      <td>0.043280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 10:52</th>\n",
       "      <td>0.061289</td>\n",
       "      <td>0.074106</td>\n",
       "      <td>0.076946</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 11:02</th>\n",
       "      <td>0.061656</td>\n",
       "      <td>0.074760</td>\n",
       "      <td>0.076070</td>\n",
       "      <td>0.043548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 11:12</th>\n",
       "      <td>0.060574</td>\n",
       "      <td>0.073734</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.044990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Bearing 1  Bearing 2  Bearing 3  Bearing 4\n",
       "2/15/2004 10:32   0.060959   0.074498   0.076289   0.043229\n",
       "2/15/2004 10:42   0.060307   0.073227   0.075189   0.043280\n",
       "2/15/2004 10:52   0.061289   0.074106   0.076946   0.043786\n",
       "2/15/2004 11:02   0.061656   0.074760   0.076070   0.043548\n",
       "2/15/2004 11:12   0.060574   0.073734   0.078335   0.044990"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_df = pd.read_csv(training_dataset, index_col=0)\n",
    "train_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset='data/transform/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearing 1</th>\n",
       "      <th>Bearing 2</th>\n",
       "      <th>Bearing 3</th>\n",
       "      <th>Bearing 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2/15/2004 13:02</th>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>0.044803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 13:12</th>\n",
       "      <td>0.059932</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>0.075502</td>\n",
       "      <td>0.044021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 13:22</th>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.043490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 13:32</th>\n",
       "      <td>0.060587</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.077079</td>\n",
       "      <td>0.044251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/15/2004 13:42</th>\n",
       "      <td>0.062083</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.077464</td>\n",
       "      <td>0.043866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Bearing 1  Bearing 2  Bearing 3  Bearing 4\n",
       "2/15/2004 13:02   0.061667   0.074043   0.076449   0.044803\n",
       "2/15/2004 13:12   0.059932   0.074051   0.075502   0.044021\n",
       "2/15/2004 13:22   0.059952   0.073974   0.076825   0.043490\n",
       "2/15/2004 13:32   0.060587   0.074444   0.077079   0.044251\n",
       "2/15/2004 13:42   0.062083   0.074579   0.077464   0.043866"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_df = pd.read_csv(test_dataset, index_col=0)\n",
    "test_input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket=sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input location\n",
    "common_prefix = \"anomaly-detection-in-iot-data\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "TRAINING_WORKDIR = \"data/training\"\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/anomaly-detection-in-iot-data/batch-inference-input-data/unlabelled.csv\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/unlabelled.csv\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a machine learning model\n",
    "\n",
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = AlgorithmEstimator(\n",
    "    algorithm_arn=algorithm_arn,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    base_job_name='anomaly-detection-in-iot-data-marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run the training job using algorithm arn arn:aws:sagemaker:us-east-2:786796469737:algorithm/anomaly-detection-in-iot-data in region us-east-2\n",
      "2021-11-10 12:52:00 Starting - Starting the training job...\n",
      "2021-11-10 12:52:23 Starting - Launching requested ML instancesProfilerReport-1636548720: InProgress\n",
      "...\n",
      "2021-11-10 12:52:52 Starting - Preparing the instances for training.........\n",
      "2021-11-10 12:54:23 Downloading - Downloading input data...\n",
      "2021-11-10 12:54:43 Training - Downloading the training image......\n",
      "2021-11-10 12:55:56 Uploading - Uploading generated training model\u001b[34m2021-11-10 12:55:43.672775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 12:55:43.672859: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34m2021-11-10 12:55:47.400021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 12:55:47.400090: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-11-10 12:55:47.400128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-228-182.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-11-10 12:55:47.400456: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2021-11-10 12:55:47.807969: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34mEpoch 1/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 3s - loss: 0.4815#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 4s 513ms/step - loss: 0.4671 - val_loss: 0.5442\u001b[0m\n",
      "\u001b[34mEpoch 2/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4603#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4650 - val_loss: 0.5418\u001b[0m\n",
      "\u001b[34mEpoch 3/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4806#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.4629 - val_loss: 0.5394\u001b[0m\n",
      "\u001b[34mEpoch 4/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4476#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 22ms/step - loss: 0.4608 - val_loss: 0.5369\u001b[0m\n",
      "\u001b[34mEpoch 5/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4827#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 19ms/step - loss: 0.4586 - val_loss: 0.5344\u001b[0m\n",
      "\u001b[34mEpoch 6/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4353#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4566 - val_loss: 0.5319\u001b[0m\n",
      "\u001b[34mEpoch 7/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.5047#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4544 - val_loss: 0.5293\u001b[0m\n",
      "\u001b[34mEpoch 8/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4550#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4523 - val_loss: 0.5268\u001b[0m\n",
      "\u001b[34mEpoch 9/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4381#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.4500 - val_loss: 0.5243\u001b[0m\n",
      "\u001b[34mEpoch 10/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4037#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.4479 - val_loss: 0.5217\u001b[0m\n",
      "\u001b[34mEpoch 11/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4423#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4457 - val_loss: 0.5191\u001b[0m\n",
      "\u001b[34mEpoch 12/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4179#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4434 - val_loss: 0.5165\u001b[0m\n",
      "\u001b[34mEpoch 13/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4213#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4411 - val_loss: 0.5138\u001b[0m\n",
      "\u001b[34mEpoch 14/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4679#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4388 - val_loss: 0.5111\u001b[0m\n",
      "\u001b[34mEpoch 15/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4458#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4365 - val_loss: 0.5083\u001b[0m\n",
      "\u001b[34mEpoch 16/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4783#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4342 - val_loss: 0.5055\u001b[0m\n",
      "\u001b[34mEpoch 17/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4343#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4318 - val_loss: 0.5027\u001b[0m\n",
      "\u001b[34mEpoch 18/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4658#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.4295 - val_loss: 0.4999\u001b[0m\n",
      "\u001b[34mEpoch 19/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3948#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4270 - val_loss: 0.4971\u001b[0m\n",
      "\u001b[34mEpoch 20/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4383#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4246 - val_loss: 0.4943\u001b[0m\n",
      "\u001b[34mEpoch 21/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4548#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4222 - val_loss: 0.4914\u001b[0m\n",
      "\u001b[34mEpoch 22/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4506#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.4199 - val_loss: 0.4885\u001b[0m\n",
      "\u001b[34mEpoch 23/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3951#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.4174 - val_loss: 0.4856\u001b[0m\n",
      "\u001b[34mEpoch 24/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4187#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.4151 - val_loss: 0.4826\u001b[0m\n",
      "\u001b[34mEpoch 25/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3985#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 36ms/step - loss: 0.4126 - val_loss: 0.4796\u001b[0m\n",
      "\u001b[34mEpoch 26/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3873#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 19ms/step - loss: 0.4101 - val_loss: 0.4765\u001b[0m\n",
      "\u001b[34mEpoch 27/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4230#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 26ms/step - loss: 0.4076 - val_loss: 0.4734\u001b[0m\n",
      "\u001b[34mEpoch 28/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3266#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 23ms/step - loss: 0.4051 - val_loss: 0.4702\u001b[0m\n",
      "\u001b[34mEpoch 29/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3832#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 21ms/step - loss: 0.4024 - val_loss: 0.4670\u001b[0m\n",
      "\u001b[34mEpoch 30/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4114#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 24ms/step - loss: 0.3999 - val_loss: 0.4637\u001b[0m\n",
      "\u001b[34mEpoch 31/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3868#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 23ms/step - loss: 0.3971 - val_loss: 0.4604\u001b[0m\n",
      "\u001b[34mEpoch 32/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4084#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 19ms/step - loss: 0.3945 - val_loss: 0.4570\u001b[0m\n",
      "\u001b[34mEpoch 33/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3947#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3919 - val_loss: 0.4537\u001b[0m\n",
      "\u001b[34mEpoch 34/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3527#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3891 - val_loss: 0.4503\u001b[0m\n",
      "\u001b[34mEpoch 35/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3609#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3865 - val_loss: 0.4468\u001b[0m\n",
      "\u001b[34mEpoch 36/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3769#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 23ms/step - loss: 0.3838 - val_loss: 0.4432\u001b[0m\n",
      "\u001b[34mEpoch 37/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3760#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 20ms/step - loss: 0.3810 - val_loss: 0.4396\u001b[0m\n",
      "\u001b[34mEpoch 38/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3635#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3781 - val_loss: 0.4360\u001b[0m\n",
      "\u001b[34mEpoch 39/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3562#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3753 - val_loss: 0.4322\u001b[0m\n",
      "\u001b[34mEpoch 40/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3717#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.4284\u001b[0m\n",
      "\u001b[34mEpoch 41/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4035#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.4246\u001b[0m\n",
      "\u001b[34mEpoch 42/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3516#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 22ms/step - loss: 0.3662 - val_loss: 0.4206\u001b[0m\n",
      "\u001b[34mEpoch 43/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2944#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 21ms/step - loss: 0.3631 - val_loss: 0.4165\u001b[0m\n",
      "\u001b[34mEpoch 44/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.4174#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3602 - val_loss: 0.4124\u001b[0m\n",
      "\u001b[34mEpoch 45/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3430#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3568 - val_loss: 0.4082\u001b[0m\n",
      "\u001b[34mEpoch 46/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3610#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3540 - val_loss: 0.4039\u001b[0m\n",
      "\u001b[34mEpoch 47/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3366#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 22ms/step - loss: 0.3506 - val_loss: 0.3996\u001b[0m\n",
      "\u001b[34mEpoch 48/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3570#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3473 - val_loss: 0.3951\u001b[0m\n",
      "\u001b[34mEpoch 49/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3937#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3441 - val_loss: 0.3905\u001b[0m\n",
      "\u001b[34mEpoch 50/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3618#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3407 - val_loss: 0.3857\u001b[0m\n",
      "\u001b[34mEpoch 51/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3484#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3372 - val_loss: 0.3809\u001b[0m\n",
      "\u001b[34mEpoch 52/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3499#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 19ms/step - loss: 0.3338 - val_loss: 0.3758\u001b[0m\n",
      "\u001b[34mEpoch 53/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2598#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3301 - val_loss: 0.3706\u001b[0m\n",
      "\u001b[34mEpoch 54/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2827#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.3264 - val_loss: 0.3652\u001b[0m\n",
      "\u001b[34mEpoch 55/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3128#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3230 - val_loss: 0.3610\u001b[0m\n",
      "\u001b[34mEpoch 56/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3320#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3191 - val_loss: 0.3582\u001b[0m\n",
      "\u001b[34mEpoch 57/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2992#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3155 - val_loss: 0.3554\u001b[0m\n",
      "\u001b[34mEpoch 58/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3059#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3118 - val_loss: 0.3525\u001b[0m\n",
      "\u001b[34mEpoch 59/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2866#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3080 - val_loss: 0.3495\u001b[0m\n",
      "\u001b[34mEpoch 60/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2555#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3041 - val_loss: 0.3463\u001b[0m\n",
      "\u001b[34mEpoch 61/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3449#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.3006 - val_loss: 0.3429\u001b[0m\n",
      "\u001b[34mEpoch 62/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2866#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2961 - val_loss: 0.3395\u001b[0m\n",
      "\u001b[34mEpoch 63/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3354#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2919 - val_loss: 0.3359\u001b[0m\n",
      "\u001b[34mEpoch 64/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2991#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2878 - val_loss: 0.3321\u001b[0m\n",
      "\u001b[34mEpoch 65/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2590#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2831 - val_loss: 0.3282\u001b[0m\n",
      "\u001b[34mEpoch 66/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.3084#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.2793 - val_loss: 0.3240\u001b[0m\n",
      "\u001b[34mEpoch 67/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2832#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2754 - val_loss: 0.3197\u001b[0m\n",
      "\u001b[34mEpoch 68/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2746#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2712 - val_loss: 0.3152\u001b[0m\n",
      "\u001b[34mEpoch 69/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2847#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2680 - val_loss: 0.3103\u001b[0m\n",
      "\u001b[34mEpoch 70/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2409#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.2633 - val_loss: 0.3052\u001b[0m\n",
      "\u001b[34mEpoch 71/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2547#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2598 - val_loss: 0.2999\u001b[0m\n",
      "\u001b[34mEpoch 72/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2394#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2555 - val_loss: 0.2942\u001b[0m\n",
      "\u001b[34mEpoch 73/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2517#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2527 - val_loss: 0.2881\u001b[0m\n",
      "\u001b[34mEpoch 74/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2347#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2489 - val_loss: 0.2817\u001b[0m\n",
      "\u001b[34mEpoch 75/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2264#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2452 - val_loss: 0.2749\u001b[0m\n",
      "\u001b[34mEpoch 76/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2570#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2428 - val_loss: 0.2680\u001b[0m\n",
      "\u001b[34mEpoch 77/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2498#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2391 - val_loss: 0.2612\u001b[0m\n",
      "\u001b[34mEpoch 78/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2230#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2363 - val_loss: 0.2542\u001b[0m\n",
      "\u001b[34mEpoch 79/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2255#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2325 - val_loss: 0.2472\u001b[0m\n",
      "\u001b[34mEpoch 80/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.1934#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2299 - val_loss: 0.2406\u001b[0m\n",
      "\u001b[34mEpoch 81/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2340#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2271 - val_loss: 0.2394\u001b[0m\n",
      "\u001b[34mEpoch 82/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2337#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2250 - val_loss: 0.2384\u001b[0m\n",
      "\u001b[34mEpoch 83/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2430#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2227 - val_loss: 0.2375\u001b[0m\n",
      "\u001b[34mEpoch 84/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2323#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2202 - val_loss: 0.2364\u001b[0m\n",
      "\u001b[34mEpoch 85/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2219#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2191 - val_loss: 0.2350\u001b[0m\n",
      "\u001b[34mEpoch 86/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2022#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2172 - val_loss: 0.2334\u001b[0m\n",
      "\u001b[34mEpoch 87/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.1990#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2152 - val_loss: 0.2318\u001b[0m\n",
      "\u001b[34mEpoch 88/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2416#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2152 - val_loss: 0.2301\u001b[0m\n",
      "\u001b[34mEpoch 89/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2143#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2141 - val_loss: 0.2284\u001b[0m\n",
      "\u001b[34mEpoch 90/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2074#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2133 - val_loss: 0.2271\u001b[0m\n",
      "\u001b[34mEpoch 91/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2167#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.2125 - val_loss: 0.2259\u001b[0m\n",
      "\u001b[34mEpoch 92/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.1988#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2118 - val_loss: 0.2241\u001b[0m\n",
      "\u001b[34mEpoch 93/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2115#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2110 - val_loss: 0.2224\u001b[0m\n",
      "\u001b[34mEpoch 94/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.1938#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 22ms/step - loss: 0.2099 - val_loss: 0.2204\u001b[0m\n",
      "\u001b[34mEpoch 95/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2186#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.2090 - val_loss: 0.2181\u001b[0m\n",
      "\u001b[34mEpoch 96/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2007#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 18ms/step - loss: 0.2081 - val_loss: 0.2157\u001b[0m\n",
      "\u001b[34mEpoch 97/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2145#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2068 - val_loss: 0.2130\u001b[0m\n",
      "\u001b[34mEpoch 98/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2020#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2057 - val_loss: 0.2100\u001b[0m\n",
      "\u001b[34mEpoch 99/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.1988#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2043 - val_loss: 0.2071\u001b[0m\n",
      "\u001b[34mEpoch 100/100\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.2171#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 0s 17ms/step - loss: 0.2032 - val_loss: 0.2040\u001b[0m\n",
      "\u001b[34mModel saved\u001b[0m\n",
      "\u001b[34mmodel saved\u001b[0m\n",
      "\u001b[34mtraining complete\u001b[0m\n",
      "\u001b[34mSucess\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-10 12:56:24 Completed - Training job completed\n",
      "Training seconds: 101\n",
      "Billable seconds: 101\n"
     ]
    }
   ],
   "source": [
    "print (\"Now run the training job using algorithm arn %s in region %s\" % (algorithm_arn, sagemaker_session.boto_region_name))\n",
    "algo.fit({'training': training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy model and verify results\n",
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='anomaly-detection-in-iot-data-1'\n",
    "\n",
    "content_type='text/csv'\n",
    "\n",
    "real_time_inference_instance_type='ml.c4.xlarge'\n",
    "batch_transform_inference_instance_type='ml.c4.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "#Deploy the model\n",
    "predictor = algo.deploy(1, 'ml.c4.xlarge',endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint is created, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/transform/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name 'anomaly-detection-in-iot-data-1' \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type 'text/csv' \\\n",
    "    --region us-east-2 \\\n",
    "    \"output.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearing 1</th>\n",
       "      <th>Bearing 2</th>\n",
       "      <th>Bearing 3</th>\n",
       "      <th>Bearing 4</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059932</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>0.075502</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.043490</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060587</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.077079</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062083</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.077464</td>\n",
       "      <td>0.043866</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.060754</td>\n",
       "      <td>0.074319</td>\n",
       "      <td>0.077035</td>\n",
       "      <td>0.043082</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.074256</td>\n",
       "      <td>0.077871</td>\n",
       "      <td>0.043901</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.062129</td>\n",
       "      <td>0.074085</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.061882</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0.075903</td>\n",
       "      <td>0.044326</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061170</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>0.074654</td>\n",
       "      <td>0.044231</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bearing 1  Bearing 2  Bearing 3  Bearing 4 Anomaly\n",
       "0   0.061667   0.074043   0.076449   0.044803      No\n",
       "1   0.059932   0.074051   0.075502   0.044021      No\n",
       "2   0.059952   0.073974   0.076825   0.043490      No\n",
       "3   0.060587   0.074444   0.077079   0.044251      No\n",
       "4   0.062083   0.074579   0.077464   0.043866      No\n",
       "5   0.060754   0.074319   0.077035   0.043082      No\n",
       "6   0.062053   0.074256   0.077871   0.043901      No\n",
       "7   0.062129   0.074085   0.077453   0.044017      No\n",
       "8   0.061882   0.073684   0.075903   0.044326      No\n",
       "9   0.061170   0.073761   0.074654   0.044231      No"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv(\"output.csv\")\n",
    "output.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint\n",
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform Batch inference\n",
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/anomaly-detection-in-iot-data/batch-inference-input-data/test.csv\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/test.csv\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "................................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [13] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.712753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.712820: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.792890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.793393: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.858018: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.858085: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.916349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.916500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455110: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455155: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d18f6684d48): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Nov/2021:13:13:42 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Nov/2021:13:13:42 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34minside predict                  Bearing 1  Bearing 2  Bearing 3  Bearing 4\u001b[0m\n",
      "\u001b[34m2/15/2004 13:02   0.061667   0.074043   0.076449   0.044803\u001b[0m\n",
      "\u001b[34m2/15/2004 13:12   0.059932   0.074051   0.075502   0.044021\u001b[0m\n",
      "\u001b[34m2/15/2004 13:22   0.059952   0.073974   0.076825   0.043490\u001b[0m\n",
      "\u001b[34m2/15/2004 13:32   0.060587   0.074444   0.077079   0.044251\u001b[0m\n",
      "\u001b[34m2/15/2004 13:42   0.062083   0.074579   0.077464   0.043866\u001b[0m\n",
      "\u001b[34m...                    ...        ...        ...        ...\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34m[537 rows x 4 columns]\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198286: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d18f6684d48): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mMinMaxScaler() 0.3850999965713459\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.850829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34mprediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Nov/2021:13:13:43 +0000] \"POST /invocations HTTP/1.1\" 200 4582 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m2021-11-10T13:13:42.104:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [13] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-11-10 13:13:33 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.712753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.712820: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [13] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35m[2021-11-10 13:13:33 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.712753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.712820: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.792890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.793393: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.858018: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.858085: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.916349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:34.916500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.792890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.793393: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.858018: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.858085: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.916349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:34.916500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455110: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455155: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d18f6684d48): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:41.455613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Nov/2021:13:13:42 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Nov/2021:13:13:42 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34minside predict                  Bearing 1  Bearing 2  Bearing 3  Bearing 4\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:41.455057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:41.455110: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:41.455155: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d18f6684d48): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:41.455613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/Nov/2021:13:13:42 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/Nov/2021:13:13:42 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35minside predict                  Bearing 1  Bearing 2  Bearing 3  Bearing 4\u001b[0m\n",
      "\u001b[34m2/15/2004 13:02   0.061667   0.074043   0.076449   0.044803\u001b[0m\n",
      "\u001b[35m2/15/2004 13:02   0.061667   0.074043   0.076449   0.044803\u001b[0m\n",
      "\u001b[34m2/15/2004 13:12   0.059932   0.074051   0.075502   0.044021\u001b[0m\n",
      "\u001b[34m2/15/2004 13:22   0.059952   0.073974   0.076825   0.043490\u001b[0m\n",
      "\u001b[34m2/15/2004 13:32   0.060587   0.074444   0.077079   0.044251\u001b[0m\n",
      "\u001b[34m2/15/2004 13:42   0.062083   0.074579   0.077464   0.043866\u001b[0m\n",
      "\u001b[35m2/15/2004 13:12   0.059932   0.074051   0.075502   0.044021\u001b[0m\n",
      "\u001b[35m2/15/2004 13:22   0.059952   0.073974   0.076825   0.043490\u001b[0m\n",
      "\u001b[35m2/15/2004 13:32   0.060587   0.074444   0.077079   0.044251\u001b[0m\n",
      "\u001b[35m2/15/2004 13:42   0.062083   0.074579   0.077464   0.043866\u001b[0m\n",
      "\u001b[34m...                    ...        ...        ...        ...\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[35m...                    ...        ...        ...        ...\u001b[0m\n",
      "\u001b[35mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[35mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[35mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[35mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[34m[537 rows x 4 columns]\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35mNaN                    NaN        NaN        NaN        NaN\u001b[0m\n",
      "\u001b[35m[537 rows x 4 columns]\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:42.198236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198286: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d18f6684d48): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.198684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:42.198286: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:42.198328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d18f6684d48): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:42.198684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mMinMaxScaler() 0.3850999965713459\u001b[0m\n",
      "\u001b[34m2021-11-10 13:13:42.850829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34mprediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Nov/2021:13:13:43 +0000] \"POST /invocations HTTP/1.1\" 200 4582 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mMinMaxScaler() 0.3850999965713459\u001b[0m\n",
      "\u001b[35m2021-11-10 13:13:42.850829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[35mprediction\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/Nov/2021:13:13:43 +0000] \"POST /invocations HTTP/1.1\" 200 4582 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-11-10T13:13:42.104:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-786796469737/anomaly-detection-in-iot-data-marketpla-2021-11-10-13-08-25-535\n"
     ]
    }
   ],
   "source": [
    "transformer = algo.transformer(1, 'ml.m4.xlarge')\n",
    "transformer.transform(transform_input, content_type='text/csv')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/anomaly-detection-in-iot-data-marketpla-2021-11-10-13-08-25-535'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], \"test.csv\")\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketFolder = transformer.output_path.rsplit('/')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=bucket\n",
    "with open('output.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, bucketFolder+'/' + \"test.csv\" +'.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearing 1</th>\n",
       "      <th>Bearing 2</th>\n",
       "      <th>Bearing 3</th>\n",
       "      <th>Bearing 4</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059932</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>0.075502</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.043490</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060587</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.077079</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062083</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.077464</td>\n",
       "      <td>0.043866</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.060754</td>\n",
       "      <td>0.074319</td>\n",
       "      <td>0.077035</td>\n",
       "      <td>0.043082</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.074256</td>\n",
       "      <td>0.077871</td>\n",
       "      <td>0.043901</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.062129</td>\n",
       "      <td>0.074085</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.061882</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0.075903</td>\n",
       "      <td>0.044326</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061170</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>0.074654</td>\n",
       "      <td>0.044231</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bearing 1  Bearing 2  Bearing 3  Bearing 4 Anomaly\n",
       "0   0.061667   0.074043   0.076449   0.044803      No\n",
       "1   0.059932   0.074051   0.075502   0.044021      No\n",
       "2   0.059952   0.073974   0.076825   0.043490      No\n",
       "3   0.060587   0.074444   0.077079   0.044251      No\n",
       "4   0.062083   0.074579   0.077464   0.043866      No\n",
       "5   0.060754   0.074319   0.077035   0.043082      No\n",
       "6   0.062053   0.074256   0.077871   0.043901      No\n",
       "7   0.062129   0.074085   0.077453   0.044017      No\n",
       "8   0.061882   0.073684   0.075903   0.044326      No\n",
       "9   0.061170   0.073761   0.074654   0.044231      No"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)\n",
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Detection in IoT Data.ipynb\r\n",
      "data/\r\n",
      "data/training/\r\n",
      "data/training/train.csv\r\n",
      "data/training/.ipynb_checkpoints/\r\n",
      "data/.ipynb_checkpoints/\r\n",
      "data/transform/\r\n",
      "data/transform/test.csv\r\n",
      "data/transform/.ipynb_checkpoints/\r\n",
      "output.csv\r\n"
     ]
    }
   ],
   "source": [
    "!tar cvfz allfiles.zip *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
